{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
  "state": {}
},

    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"transformers>=4.42.0\" \"peft>=0.11.1\" \"trl>=0.9.4\" \"accelerate>=0.34.0\" bitsandbytes datasets evaluate rouge_score einops scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udF7qYlFd98r",
        "outputId": "59c2f983-adbb-47e3-de62-77ee40f6967d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.42.0 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: peft>=0.11.1 in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Collecting peft>=0.11.1\n",
            "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting trl>=0.9.4\n",
            "  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft>=0.11.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft>=0.11.1) (2.8.0+cu126)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.42.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.42.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.0) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft>=0.11.1) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft>=0.11.1) (3.0.3)\n",
            "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.25.1-py3-none-any.whl (465 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=bfe0ab89596cd7172b691101da4a3c2e328360f6310bd02c0602c5c547b86a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: pyarrow, rouge_score, datasets, bitsandbytes, trl, peft, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.1\n",
            "    Uninstalling peft-0.17.1:\n",
            "      Successfully uninstalled peft-0.17.1\n",
            "Successfully installed bitsandbytes-0.48.2 datasets-4.4.1 evaluate-0.4.6 peft-0.18.0 pyarrow-22.0.0 rouge_score-0.1.2 trl-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import tqdm\n",
        "from transformers import (BitsAndBytesConfig,AutoTokenizer,AutoModelForCausalLM,Trainer)\n",
        "from huggingface_hub import interpreter_login\n",
        "from functools import partial\n",
        "from peft import LoraConfig,get_peft_model, prepare_model_for_kbit_training\n",
        "interpreter_login()"
      ],
      "metadata": {
        "id": "clnCa2AD-WmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c38f30-88ff-402c-c404-b6d4f70642ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "Enter your token (input will not be visible): ··········\n",
            "Add token as git credential? (Y/n) y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hugging_face_dataset=\"neil-code/dialogsum-test\"\n",
        "dataset=load_dataset(hugging_face_dataset)"
      ],
      "metadata": {
        "id": "CeJJaKl1BJ7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "59b138d012114f488586ca1e86050def",
            "7b502a222b9b41c2960696e537944e3b",
            "2cae2151860243a995d596deb4f02a01",
            "224f83e459534f3a9796417cb43fbc40",
            "ed8b87ecdf7d4530897d519dfc4e93da",
            "95a212fd337a4cb686bc8699ec41afa3",
            "a7a0807f3cad4d849e16ee18008d79f9",
            "21d88fc7189c43b49675709bf53e491d",
            "13c91d9ae5d6426dbaca043feed32359",
            "acee1b169f5942698c552fc1ba7cdf0f",
            "124392c96e254a85918686358408a317",
            "44a7db9b0e284a06a448e66b24b175d3",
            "1b60a96d087f4dbab542c91d70c64f0e",
            "974adb744d0342138e44f07e780f9868",
            "501dd964f7ae4fadbf7434b9d5da42d2",
            "fc480de72e99402fa50cb83f6b1838a5",
            "3bdf198984b64f919ea6dc85e198a66d",
            "8d59b1dda2784992afcde1fda641595a",
            "087f87200c0c4d76ad5cc5d36e47e8d7",
            "fa67af2032e14d8481821d7b0c2773a0",
            "878cd223f28f461ea7147fc361f40de5",
            "32935c35ed024e1ba408a635b40f0b34",
            "06f594fd77484bf894ec52af504bf0e6",
            "03944dc1ad5148609af2e5ec20e8b145",
            "425428d5415f44e49fbb62f9c12051e5",
            "b1cc6483e4614cadb1c3d753413bc262",
            "e540e3e3f91244ee8880c24e656c889a",
            "960679e7f3524752abfdf2ed45a8eaa2",
            "8f28355a20344e5cb56d79ac7f7b2b7c",
            "24576566dc2343e8a913851d21862cbf",
            "9fa410215213493b9ddd50401e34aa73",
            "3e2d9f1ad43b4b488b060f71abae6af8",
            "ec2b4b339246472eb90667297bc68ee4",
            "c56e1ce0ad4e477d98dd1727078e7809",
            "ff1ca17256ef447dabfb5ef942f9d50f",
            "3ef039c8297741edb09b66ef5abece8a",
            "2842586916a04a99b10c305296591e95",
            "663f3057ed334f599919f1196f88642b",
            "bc7e5ff6e8d840d78d18508a0b613cb0",
            "9cae4cc9f4a649c1b39dda5e8a24c7b6",
            "58ed28a42bf64611b9e382e11febdec3",
            "b179dddffb304473949cacdf7c62134f",
            "0747f3a3d0a643cc8f10b5b8c24081ea",
            "dd7211ac58a6400281967184bc85168a",
            "eb150e8382f442fd93553e9be52b853a",
            "41a9fc116d8f4a55b9bf4023b7029c6c",
            "875b5cf29f214a6aa660efefbd8947f5",
            "46a8548ae51b43c292a90527ace55dc3",
            "56cfc0cacd774bda9775872cfb36e97b",
            "d309f12a07af410698d38d4a94caa0f7",
            "2b0b0baae66543c1ba7ec5c7a2942557",
            "b88fed6bd2f840a4856b873335453738",
            "152da2f5223540de9cebd7195a67ee11",
            "2cd100429d644adbafb31001002ed9b5",
            "e11ca1e6efac4053b950370f590f77dd",
            "d2f7450edf734d33ba6f586770dffbd2",
            "bcc9085db9a54b33871145ce72983e54",
            "5b3722087b5f42cbb4cf4007044549c9",
            "0b032aa54a874bc0b2194be3e278ebfa",
            "97fdced7b3d142d198d08eb49a4e78c8",
            "af1ae28437904d86bd49781c31a06771",
            "5e28e9345c1c4347864c44b252f6f13e",
            "21a845a2fdc6496bab623191c4e782b5",
            "227a2ab454b540c298eb25b63c9a8689",
            "304caf48174042798cf0effb78577d67",
            "ce0f31d64d3a43cca901740aa5696676",
            "2cf580426d3a4dcf8a100b9aae5654d2",
            "4478c1ec5ba548c29a1825031df30e10",
            "2d99537e5c9745459dd66f7855a60c9f",
            "87d46fb8e48545a0bbeea943fb77a770",
            "4cccef9929b04024ba21f53bf879c0ee",
            "2366393329db468a96fa437212bea21d",
            "1039b6d599cb4e93a372b698fb71daeb",
            "0353d69b9b574179a516b89586c80e8f",
            "8159573da72846e2b3381439e2bf2fb0",
            "fe5050fcc2974c94be7e4e8b20f3d456",
            "334e11015e8f48dd9cbaa11c5986f4c7"
          ]
        },
        "collapsed": true,
        "outputId": "0928d827-f7f0-4d2b-8f6f-e9fd76b9803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59b138d012114f488586ca1e86050def"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44a7db9b0e284a06a448e66b24b175d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f594fd77484bf894ec52af504bf0e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c56e1ce0ad4e477d98dd1727078e7809"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb150e8382f442fd93553e9be52b853a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/499 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2f7450edf734d33ba6f586770dffbd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/499 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cf580426d3a4dcf8a100b9aae5654d2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87cco_qQBf20",
        "outputId": "8685070d-f0d1-4da5-ec16-aff2b161cb44",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1999\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeIXVcTXBsOL",
        "outputId": "5c957d92-c7e4-403e-8048-4d40b3a7853c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'train_0',\n",
              " 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\",\n",
              " 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
              " 'topic': 'get a check-up'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype=getattr(torch,\"float16\")\n",
        "bnb_config=BitsAndBytesConfig(\n",
        "    Load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype\n",
        ")"
      ],
      "metadata": {
        "id": "eJu23Z0FC9o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"microsoft/phi-2\"\n",
        "device_map={\"\":0}\n",
        "original_model=AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                                    quantization_config=bnb_config,\n",
        "                                                    device_map=device_map,\n",
        "                                                    trust_remote_code=True,\n",
        "                                                    use_auth_token=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "70de2f4940084d0cb93625140975ebe1",
            "3b1290dca2a24748a4370f1ef010edb6",
            "ba27cb5b961c4135baff051affd62060",
            "ad53a89ec7cb4d2fa50daca797d63f61",
            "0c5efa7ac16749d3b41b719739ac522b",
            "b66544d5cb8549c3b58941ee2ad9485e",
            "a91b9752bf2940a0a4b2556bacdfb045",
            "418eed6389af49a5b80b4a1c427c8722",
            "28d7cd90296640929368de757168c3df",
            "8feb749ed2bb412899ee683e2d9ace87",
            "27310558933a484193f8c370bba088a2",
            "8c2b2b3a11c74196a5ae42aa33207ab7",
            "09ed11e1225a43e8b28aec04adab888e",
            "bd9de9071746484592ba74dab8655f0a",
            "67de441477bd40a5973a98ca9a252d3f",
            "58f1f5394ccb45a1873da8fe1bf0cbd1",
            "296150d84f954dea9b2ebce0c30ca1dc",
            "027198915fe54c26babcb551f5e07755",
            "a5c12e07e7a4463c84b00d2b25641eb5",
            "fa30d90643204b4f9769c30af8e26a0a",
            "ddd77e6342b44c2ea102725714e50922",
            "881edb21da9d47aa8b19a8138cea0064",
            "9d96ab7b51f94b3a9ac1773683b0e099",
            "644f807debc048d38e1ce390631cac47",
            "cc02660afc144c89a1a85b0e56cd5f55",
            "299961547fd54f7fbe20dc548fbbe5bb",
            "34f9d904cf3842d48c5ce4f5d1093b6d",
            "bc0bd98d4f3142508c945c522c957029",
            "970075bf9b944e0c821950dddc75b3d2",
            "585ee7498d0a436c92a94a7c669d7fbc",
            "3bfbbd6b5e77467f9f9761e336476314",
            "e293102b0b10499898c1e01bf0d7c9ad",
            "878ced47c634461aafc5cf77e32d4e54",
            "71e1f739fac947969beb1e71808e35a5",
            "739ab188d10140c6b9fa315bb26de8cb",
            "1c8e5e490590459891223b92c8edd8aa",
            "5b6495b23397471f9a1d5183808282af",
            "fb74114cf92346b5ae9c9f7bfad423b4",
            "effd92023df1426093d24b5b23cf70b9",
            "5a3f147e087d41579685dffcfeb06a11",
            "9c564877646d46cfa3b55c16f95c3004",
            "31ed4eae65f141c4832c871730caa8b6",
            "6ad0688b786243cd8df276b5242eaff8",
            "bb781be6104442a1a1607255decfeadf",
            "d7896bf53cae44af832f3aca97aaa4d9",
            "f9c65240e53c47a0a615956afd62f0df",
            "826ba633e4df448386a1c8e6aa72bd1b",
            "73a287d29e9540b3910cae6c4908cd65",
            "40c88292a8c14cd2a56024fa8716ab2f",
            "6aec5b28e902481bb81cd3e77a2d36a2",
            "5781126dd8a7496c87af9a47d023a345",
            "406fa133c7bd43a39eca1e729d3b5044",
            "b666195567cb4317afaa558ae69a4124",
            "34b49f7c1eec41638f88cb6c0b3141f8",
            "97845f1723394643a1215e2eb03bd015",
            "dcb729e30582414a8387a667702a66a8",
            "5bd7f45d65d048f9ac196030ff4b769d",
            "bcb91947d29748459e66f93edd7445b8",
            "9de68b08adca4f72b11c157f39754596",
            "b0cc5adf9e3e4cfd820a17dba157c6c0",
            "22cbc947a5524b55a65eec61e1f35404",
            "9b5b1b3af0774e24a1d379ed4cadab93",
            "645163f2a701436bbf8424281f8ad348",
            "586aecc86fc84dadb7b3bc3cb5319f9a",
            "86245e859e704271b1ab090d4b0d49d4",
            "fa0ef96a57a4433b9ed177fc3b47a061",
            "38d584a627af461dbc42e6bfe02aa885",
            "ad0e41e7eaa3442ba07394874f112a8c",
            "63c286d7d0f748f7a8f6fea07356ebe8",
            "e0b01d81f387477bbc401a02402dfe12",
            "0dffdfff40604e3bba3f9bb3d61bc653",
            "14683c52b79546a1ad97e11c09ef7902",
            "2a1ea28a1de3411dba314c335375fa0f",
            "135bb9c513004eee85eb93ccb085451a",
            "fd37d45e75a046b29ec3d1a1476940c8",
            "7e161cb50d78458e8c0545912badfb8e",
            "01413e082a3e453192d962528b170e05"
          ]
        },
        "id": "HpmrGZDzCCcB",
        "outputId": "39b8f531-ae2e-41db-84c3-fb79c263fd04",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70de2f4940084d0cb93625140975ebe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c2b2b3a11c74196a5ae42aa33207ab7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d96ab7b51f94b3a9ac1773683b0e099"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71e1f739fac947969beb1e71808e35a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7896bf53cae44af832f3aca97aaa4d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcb729e30582414a8387a667702a66a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38d584a627af461dbc42e6bfe02aa885"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model_name,\n",
        "                                        trust_remote_code=True,\n",
        "                                        padding_side=\"left\",\n",
        "                                        add_eos_token=True,\n",
        "                                        add_bos_token=True,\n",
        "                                        use_fast=False)\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "id": "0n5uQgpzJGIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "cf6853ab11b14425bad6d37ba2de13e4",
            "d5a821efa3654853a34e28c5431d198e",
            "7c9bb3f74e7a4f7aae0ec570345098c4",
            "b4dcba07577a47a7b7b1b014647fe78c",
            "8b0bb912b2a74646ae776571538a5fc7",
            "e974aadbb4b24a18bdf50b46c0ec064f",
            "88a499864d4c4cbc847d9baa20053886",
            "85e21e379d6c454f9f17f673569b8cce",
            "774734cfcdf94bec969a9674f2eb98b3",
            "a74e70876aa24aed981ac7675b840531",
            "30c017bcfeb64ee4b94f547bd3687e07",
            "d2f780ac31bd4e41bc6697e075481459",
            "4f81cecfec5f431daf0f828d70ca76fd",
            "4383171e9b2141aa934607b28a6bf024",
            "80b6986e4cc04b5cbc51b81df1b9b240",
            "039b7a9f649843fc91528127dc822af7",
            "88519abd913d42978ff88daafc1e6605",
            "aae4c6f303b24c789aede4fdc3ddcdd5",
            "4955e44fdd894e14af3d4c96939f24d0",
            "b6c2d46f4b0a461abf9d9609841463d9",
            "a9187a409d5f4f268e37de9480d4db0f",
            "e898214e2fc84fa0830e92c24cee5a34",
            "572b3d2153704b6a8d0d016bb7892a7a",
            "6c67cedaa07046b1b37cd7e1f96a00e3",
            "78bc8e1522d843d7a3c156d7ae312ec0",
            "be85665ef1154026861c4eaad4c6612b",
            "639e976f6e14480f993943a1c86fd3a9",
            "2d9e8ffb73734e9383780078dc8ad62b",
            "0829229960c54da7919cd4c15c49dfc1",
            "528e2d861028493ea882fb0e09c53f10",
            "3110df1be9114ab4b932f1267b944b8b",
            "50e68edc6ce242f69f563eee98c0376b",
            "d54470f2368b45a1b889e0a765599137",
            "8692fccf7c0a400e9b50de83e760c7da",
            "0c0a7fbae014455b90133d889b1a6cce",
            "2b521abae0124c68b910790252a00e8a",
            "61524cd182c6473dab9730ef7a3b84f0",
            "f2f42b3d42d3445696b1dd721e629831",
            "88ef1c894c78475ba3871833928cdc40",
            "41226f17aa2745c6b1b21a75a811af4a",
            "aa499de9c0f2462aa7819981a866dda6",
            "4244018fa6364074b9e7753419d3a672",
            "87aea7117e1b465f814fb88de5e7f20d",
            "1df65a60b2264df49e997181fcd63241",
            "16256ed3c40d4b498dd8217f7157a9b0",
            "1f652034e2184bb491fa80be7e825e32",
            "f7aa79f8feb547498596211dd7de99c2",
            "b37076bdd64b47b48e47a87dff07d161",
            "407fb45d8792433daecc77b26667debd",
            "8065071745014ceb84a2337a93e78c1b",
            "27f0a44ed3e04bd4916f35e5673ff898",
            "c01bd188fc8649828ff31dd8180b0c08",
            "40005813c1da4e90912d0cadb377f73a",
            "0bee1dd4673d46319fdb5200920bcc40",
            "56c2d5ee6b5046a59a79c1b236ab856c",
            "b705b0c6e7c64bab8d588c565aaaa0fa",
            "0c1ab92b9e234fb39a522d5896e7daaa",
            "8bc668b0d96446f6add1942f1c01dbba",
            "968fb66d0aba41649dcfe4db775a1153",
            "f7ecc449ab484db48091b197b12eb74f",
            "c8c0fb5583574b16a3913c70a37c8695",
            "58b4811deda44e069caf7e404d7c903c",
            "708c61b9bd7348d982c11efcf6da587c",
            "fedc14fd601e4c7eb3e14874c01d7da7",
            "a417572d74d64ceea53ac20b8680840d",
            "9daec6dbb68742cc86fda4a6a8375f6e"
          ]
        },
        "collapsed": true,
        "outputId": "71bffa13-05d2-4ecc-d1e1-f9a52217c1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf6853ab11b14425bad6d37ba2de13e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2f780ac31bd4e41bc6697e075481459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572b3d2153704b6a8d0d016bb7892a7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8692fccf7c0a400e9b50de83e760c7da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16256ed3c40d4b498dd8217f7157a9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b705b0c6e7c64bab8d588c565aaaa0fa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(model,tokenizer,input,max_len):\n",
        "  inputs=tokenizer(input,return_tensors=\"pt\")\n",
        "  inputs={k:v.to(\"cuda\") for k,v in inputs.items()}\n",
        "  generated_ids=model.generate(**inputs,max_new_tokens=max_len)\n",
        "  generated_output=tokenizer.batch_decode(generated_ids,skip_special_tokens=True)\n",
        "  return generated_output\n"
      ],
      "metadata": {
        "id": "F58KlxFj18J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import set_seed\n",
        "seed=42\n",
        "set_seed(seed)\n",
        "index=10\n",
        "prompt=dataset['test'][index]['dialogue']\n",
        "summary=dataset['test'][index]['summary']\n",
        "formated_prompt=f\"Instruct:Summarize the following Conversation.\\n{prompt}\\nOutput:\\n\"\n",
        "\n",
        "res=gen(original_model,tokenizer,formated_prompt,200)\n",
        "output = res[0].split('Output:\\n')[1]\n",
        "\n",
        "dash_line='-'*100\n",
        "\n",
        "print(f\"INPUT PROMPT:\\n{formated_prompt}\")\n",
        "print(dash_line)\n",
        "print(f\"SUMMARY:\\n{summary}\")\n",
        "print(dash_line)\n",
        "print(f\"MODEL GENERATION - ZERO SHOT:\\n{output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZNw-nhOrLHD",
        "outputId": "8d2f6cd3-630c-4673-9a7d-cb71b6a34791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT PROMPT:\n",
            "Instruct:Summarize the following Conversation.\n",
            "#Person1#: Happy Birthday, this is for you, Brian.\n",
            "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
            "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
            "#Person2#: Ok.\n",
            "#Person1#: This is really wonderful party.\n",
            "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
            "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
            "#Person2#: You look great, you are absolutely glowing.\n",
            "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
            "Output:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "SUMMARY:\n",
            "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Person1 and Person2 are at a party, and Person1 asks if they can have a dance. Person2 agrees and the two go to the dance floor. Person1 compliments the party and Person2 says they are popular with everyone. Person1 thanks Person2 for the compliment and says they hope their necklace goes with their dress. Person2 says they look great and Person1 agrees, saying they are glowing. Person1 suggests they have a drink together to celebrate Person2's birthday.\n",
            "\n",
            "CPU times: user 4.81 s, sys: 45.2 ms, total: 4.85 s\n",
            "Wall time: 5.67 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_format(sample):\n",
        "\n",
        "    INTRO_BLURB = \"Below is an instruction...\"\n",
        "    INSTRUCTION_KEY = \"### Instruct: Summarize the below conversation\"\n",
        "    RESPONSE_KEY = \"### Output:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"\\n{INTRO_BLURB}\"\n",
        "    instruction = f\"{INSTRUCTION_KEY}\"\n",
        "\n",
        "    input_context = sample[\"dialogue\"]\n",
        "    response = f\"{RESPONSE_KEY}\\n{sample['summary']}\"\n",
        "    end = f\"{END_KEY}\"\n",
        "\n",
        "    parts = [blurb, instruction, input_context, response, end]\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "    return sample\n"
      ],
      "metadata": {
        "id": "wj43Egpv1ksD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length(model):\n",
        "  config=model.config\n",
        "  max_length=None\n",
        "\n",
        "  for name in ['n_positions','max_position_embedddings','seq_length']:\n",
        "    max_length=getattr(config,name,None)\n",
        "    if max_length:\n",
        "      print(f\"Found max length :{max_length}\")\n",
        "      break\n",
        "  if not max_length:\n",
        "    max_length=1024\n",
        "    print(f\"Using default max length {max_length}\")\n",
        "  return max_length\n",
        "\n",
        "\n",
        "def preprocess_batch(batch,tokenizer,max_length):\n",
        "\n",
        "  return tokenizer(\n",
        "      batch['text'],\n",
        "      max_length=max_length,\n",
        "      truncation=True\n",
        "  )\n",
        "\n",
        "\n",
        "def preprocess_dataset(tokenizer:AutoTokenizer,max_length:int,seed,dataset):\n",
        "\n",
        "  print(f\"Preprocessing Dataset\")\n",
        "\n",
        "  dataset=dataset.map(create_prompt_format)\n",
        "  preprocessing_fun=partial(preprocess_batch,max_length=max_length,tokenizer=tokenizer)\n",
        "  dataset=dataset.map(preprocessing_fun,batched=True,remove_columns=['id', 'topic', 'dialogue', 'summary'])\n",
        "  dataset=dataset.filter(lambda sample :len(sample[\"input_ids\"])<max_length)\n",
        "\n",
        "  dataset=dataset.shuffle(seed)\n",
        "  return dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "gS2fSMGFgkyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=get_max_length(original_model)\n",
        "\n",
        "train_dataset=preprocess_dataset(tokenizer,max_length,seed,dataset['train'])\n",
        "eval_dataset=preprocess_dataset(tokenizer,max_length,seed,dataset['validation'])"
      ],
      "metadata": {
        "id": "L0kDzRt9rxgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261,
          "referenced_widgets": [
            "855b64e234044b7a8a1751fae7b1816c",
            "ef8d24c3a1a14a099ffe16f56d58be32",
            "b1eb4e30a41248d0bf76344dce9a6b6b",
            "cb5bf37503d849619efebc386d4aeeac",
            "2a72b4a955b0422489dc9af15c71083d",
            "c12159cb945440a0b1d973d83e993e75",
            "96ac6aa4c4a549a38db3fb33d6d83d34",
            "b0a0dbd4d1dd45369dc786f0a800c1b8",
            "36ce718f3a864f9faba22678cffb15b1",
            "918b5b81a3e4439e8684f471bd6b2bd3",
            "d81ccf4f8db64ed5a74bd7ccb1cbdae2",
            "3880d47fe44c40bc8ee0cd1ce8f2ba85",
            "e98a03dd41c4442da78644639becb862",
            "eb24889101934aa788b647dd6f3b89a8",
            "9867632b938943c2b58190d0414e3d00",
            "6c9d0cc190e24316a697695d787418e4",
            "a0693c0898b94c038f8c3346d925215a",
            "986f0659962c4cdb84cb1e5fb84b56ff",
            "2119c068310c46d58e9d315b3168025a",
            "116cd6940f6e4e1dbeb29ef754d744ee",
            "b836bc54a7444713b03f5ac969516c77",
            "175485f7bf45432bb3a96afc4bd76ef9",
            "1ea6ca01231840788f4952911b5267b8",
            "f9f6584656a74aa8996c22904acfc205",
            "3bafb0dff8a34b879e61afaece462eea",
            "1474b8e0ff7a4252ab168ca8a6cd4926",
            "505d5f6add8741ff90e6ba59a22b0553",
            "8d050494fea1428da6191dbc2052618f",
            "dcc882d02aab4c99b1dc8bb5811dc22f",
            "22a4520554394b0abb4aadae97bdcd0d",
            "da56e3fcc87643cbb5aff1c92066ab21",
            "691a31d4b88e4e6ea536342110c9a3f1",
            "2c44162419d24f92a743837b42b9078f",
            "a3f869a9797641f982c8d45ee6cd382a",
            "b8966b5eb6e04817a05585edb00b7971",
            "444966d70483491a95b8e1685957c5c2",
            "1edf7b3f8bd74d21abf8d7ea7de4e4ab",
            "14613b74b7f24ba8ac28a54ab6d5ffc6",
            "14ae8711945c436a84cef0f7c30ee386",
            "462de1098c494ab19b42a0887ee5804f",
            "1a20b87f8285482d8b2bf0b40b8584e5",
            "e9748f666dbc4e6cbc155601aecc33c2",
            "337e97f2c3334384a36d436e61b7f48c",
            "0ff492f793c845b59043a047b096a5e7",
            "8350aadd18b3497f9b983578e4dbf69b",
            "d77f0894bc064527877e1cab4f6f9373",
            "58f5026ffc6842b1b0cdcd3d4e22d128",
            "2e007b180dc7480ba905d110d0a3204b",
            "6debdb40c4a242f18a11e5aa60dc4523",
            "2adccfa38ea04473aa4682d8bec4d3ac",
            "4251d070e7fa47dd87d18dd061d7e8b5",
            "c699405c82e14fd28c285af56bedd2fb",
            "9ced16b6ec2f4b53a3a713f88961f8f1",
            "8a8b6cc6e6dc471da627faff6c376092",
            "235eda55e7874517b9f4b73554c888d9",
            "3629e142f4ca403b92896d2e24e12e30",
            "ab2197362ebd41a7b51d59e488940894",
            "f768b5e9e0864aef885d4fd6f53390ec",
            "71eeb3e730214bc2bd580465d26ca0f1",
            "5f2f3e5250dc4e01849003108e8b941b",
            "9cfff0c8477e4750ab8199a1568349b4",
            "07956be5688546efabc89633c12d0a0a",
            "8f0d4d45b8684a778b82fbf4e05338b4",
            "86d28b2d0d87432e850bd522d2c517b2",
            "f19c5d5f869443c99194e50a2dd2e482",
            "d2a69d2ae81d4212ad70f34419bf9369"
          ]
        },
        "outputId": "57f09d83-221d-4087-8e15-b31e136d6b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using default max length 1024\n",
            "Preprocessing Dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "855b64e234044b7a8a1751fae7b1816c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3880d47fe44c40bc8ee0cd1ce8f2ba85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ea6ca01231840788f4952911b5267b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing Dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3f869a9797641f982c8d45ee6cd382a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8350aadd18b3497f9b983578e4dbf69b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/499 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3629e142f4ca403b92896d2e24e12e30"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_model=prepare_model_for_kbit_training(original_model)\n",
        "\n",
        "config=LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\",\n",
        "                    \"k_proj\",\n",
        "                    \"v_proj\",\n",
        "                    \"dense\"],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\"\n",
        "\n",
        ")\n",
        "original_model.gradient_checkpointing_enable()\n",
        "peft_model=get_peft_model(original_model,config)"
      ],
      "metadata": {
        "id": "VziBm3thuAuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"Trainable params: {trainable_params}\")\n",
        "    print(f\"All params: {all_param}\")\n",
        "    print(f\"Trainable%: {100 * trainable_params / all_param:.2f}%\")\n",
        "    return trainable_params, all_param\n"
      ],
      "metadata": {
        "id": "RKlJuDF1hJqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ],
      "metadata": {
        "id": "Is9bPGXMvU6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8547c9f7-052f-45b3-fece-b8e59c269714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 20971520\n",
            "All params: 1542364160\n",
            "Trainable%: 1.36%\n",
            "(20971520, 1542364160)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "fb2C4Iqmwmtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "output_dir= f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
        "peft_training_args=TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    warmup_steps=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    max_steps=1000,\n",
        "    learning_rate=2e-4,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    logging_steps=25,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=25,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    do_eval=True,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir = 'True',\n",
        "    group_by_length=True,\n",
        ")\n",
        "peft_model.config.use_cache=False\n",
        "peft_trainer=Trainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=peft_training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "peft_trainer.train()"
      ],
      "metadata": {
        "id": "sQzwlG2aHOE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id='microsoft/phi-2'\n",
        "base_model=AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                                device_map='auto',\n",
        "                                                quantization_config=bnb_config,\n",
        "                                                trust_remote_code=True,\n",
        "                                                use_auth_token=True)"
      ],
      "metadata": {
        "id": "S3tY_emTm_BJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "06dbba74e0344ef8af66dd69921482e9",
            "de49c37561af4f88977b0d36353c42d1",
            "d331c7d5729b46ac8f95b942692e5f4e",
            "ea6d36cc1188491cbe5a5e5347fa7216",
            "522bab7665dd423a986691e2adaa160d",
            "6ce76e23e17f4614981b6eb53f45d9fa",
            "ba75558f709f440f8d4c6d9cfd955d06",
            "2bf4e1df887143a2aac0bc52d1eb9254",
            "28aef541a032464cb6a99b358befe9a1",
            "72de65816cec473c96ae6df982e9236e",
            "d825f286d4be4f6c9377b508bf3086a5"
          ]
        },
        "outputId": "9da0c99d-7d22-47a9-d810-c3d531c9bb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06dbba74e0344ef8af66dd69921482e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tokenizer=AutoTokenizer.from_pretrained(base_model_id,add_bos_token=True,trust_remote_code=True,use_fast=False)\n",
        "eval_tokenizer.pad_token=eval_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "cn4SAfUbrjyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/Colab Notebooks/my_folder/checkpoint-1000\",torch_dtype=torch.float16,is_trainable=False)"
      ],
      "metadata": {
        "id": "S4iw126esi2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "seed=42"
      ],
      "metadata": {
        "id": "HxPrqJGyJDfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set_seed(seed)\n",
        "# index=5\n",
        "# dialogue=dataset['test'][index]['dialogue']\n",
        "# summary=dataset['test'][index]['summary']\n",
        "# prompt=f'Instruct: Summarize the following Conversation.\\n {dialogue}\\noutput:\\n'\n",
        "\n",
        "# peft_model_res = gen(ft_model,eval_tokenizer,prompt,100)\n",
        "# print(peft_model_res)\n",
        "# peft_model_output = peft_model_res[0].split('output:\\n')[1]\n",
        "# #print(peft_model_output)\n",
        "# prefix, success, result = peft_model_output.partition('###')\n",
        "\n",
        "# dash_line = '-'.join('' for x in range(100))\n",
        "# print(dash_line)\n",
        "# print(f'INPUT PROMPT:\\n{prompt}')\n",
        "# print(dash_line)\n",
        "# print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "# print(dash_line)\n",
        "# print(f'PEFT MODEL:\\n{prefix}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gwyn0-jK0s6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dialogues=dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries=dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries=[]\n",
        "peft_model_summaries=[]\n",
        "\n",
        "for idx,dialogue in enumerate(dialogues):\n",
        "  human_baseline_text_output=human_baseline_summaries[idx]\n",
        "  prompt=f\"Instruct:Summarize the following conversation.\\n{dialogue}\\nOutput:\\n\"\n",
        "\n",
        "  original_model_res=gen(base_model,eval_tokenizer,prompt,200)\n",
        "  original_model_text_output=original_model_res[0].split('Output:\\n')[1]\n",
        "\n",
        "  peft_model_res=gen(ft_model,eval_tokenizer,prompt,200)\n",
        "  peft_model_output=peft_model_res[0].split('output:\\n')[1]\n",
        "  print(peft_model_output)\n",
        "  peft_model_text_output,success,result=peft_model_output.partition(\"###\")\n",
        "\n",
        "  original_model_summaries.append(original_model_text_output)\n",
        "  peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "\n",
        "zipped_summaries=list(zip(human_baseline_summaries,original_model_summaries,peft_model_summaries))\n",
        "\n",
        "df=pd.DataFrame(zipped_summaries,columns=['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\n",
        "\n"
      ],
      "metadata": {
        "id": "lvAyMJqC9FRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Frd5F8Fjjln",
        "outputId": "f6db1b3f-fdb0-4ba8-bb71-81591066090d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge=evaluate.load('rouge')\n",
        "original_model_results=rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "peft_model_results=rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)\n",
        "\n",
        "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
        "\n",
        "improvement=(np.array(list(peft_model_results.values()))-np.array(list(original_model_results.values())))\n",
        "for key,value in zip(peft_model_results.keys(),improvement):\n",
        "  print(f'{key}: {value*100:2f}%')"
      ],
      "metadata": {
        "id": "LX95BA58_El1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLdBu49H_GKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}